# SNU_2018_UROP
2018-2 UROP at SNU

## References
**Papers**
* [Distilling the Knowledge in a Neural Network](https://www.cs.toronto.edu/~hinton/absps/distillation.pdf)
* [SlimNets: An Exploration of Deep Model Compression and Acceleration](https://arxiv.org/pdf/1808.00496v1.pdf)
* [A Survey of Model Compression and Acceleration for Deep Neural Networks](https://arxiv.org/pdf/1710.09282.pdf)
* [DeepX : A Software Accelerator for Low-Power Deep Learning Inference on Mobile Devices](https://ix.cs.uoregon.edu/~jiao/papers/ipsn16.pdf)
* [DeepMon: Mobile GPU-based Deep Learning Framework for Continuous Vision Applications](https://nsr.cse.buffalo.edu/mobisys_2017/papers/pdfs/mobisys17-paper07.pdf)
* [Deep Learning for the Internet of Things](https://cse.buffalo.edu/~lusu/papers/Computer2018.pdf)
* [A Gift from Knowledge Distillation: Fast Optimization, Network Minimization and Transfer Learning](http://openaccess.thecvf.com/content_cvpr_2017/papers/Yim_A_Gift_From_CVPR_2017_paper.pdf)
* [FastDeepIoT: Towards Understanding and Optimizing Neural Network Execution Time on Mobile and Embedded Devices](https://arxiv.org/pdf/1809.06970.pdf)
* [Towards Evolutional Compression](https://arxiv.org/pdf/1707.08005.pdf)
* [Model Compression and Acceleration for Deep Neural Networks](http://cwww.ee.nctu.edu.tw/~cfung/docs/learning/cheng2018DNN_model_compression_accel.pdf)
* and possibly more... (will add later)

## Framework

* [TensorFlow](https://www.tensorflow.org)
* [Keras](https://keras.io/)
* [TensorFlow Lite](https://www.tensorflow.org/lite)
* [NNAPI](https://developer.android.com/ndk/guides/neuralnetworks/)
* possibly more
